{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4647718",
   "metadata": {},
   "source": [
    "یکی از مهمترین مباحث پردازش تصویر تقسیم بندی است،تقسیم بندی یعنی قطعه قطعه کردن تصویر به گونه ای که هر قطعه دارای معنا ومفهوم معینی باشد\n",
    "\n",
    "و بتوان از آن در پردازش ها استفاده کرد"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3a2f1",
   "metadata": {},
   "source": [
    "inRange ,روش های تقسیم بندی تصویردر فصول قبل:آستانه گیری،لبه یابی،هیستوگرام،هاف،کانتوریابی"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9b946",
   "metadata": {},
   "source": [
    "# grabCutروش های تقسیم بندی تصویر در این فصل:سوپر پیکسل ها،الگوریتم هاو"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27c67c",
   "metadata": {},
   "source": [
    "# سوپر پیکسل ها"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8003b6",
   "metadata": {},
   "source": [
    "هر تصویر دارای تعدادی پیکسل است و هر پیکسل اطلاعات مربوط به رنگ خودش را بیان میکند \n",
    "\n",
    "حال اگر چند پیکسل را به صورت یک پیکسل واحد و بزرگ در نظر گرفت که اطلاعات معناداری از تصویر را به ما میدهد \n",
    "\n",
    "به این پیکسل بزرگ ،سوپر پیکسل گفته میشودکه با گروه بندی صحیح ومحلی پیکسل های یک تصویر بدست می آید"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5ed3b",
   "metadata": {},
   "source": [
    "سوپر پیکسل ها حاوی تعدادی پیکسل هستند که از لحاظ رنگ و روشنایی شبیه هم هستند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216be7e8",
   "metadata": {},
   "source": [
    "# مهمترین مزیت سوپر پیکسل ها،تعیین مرزها ونواحی مهم در تصویر است"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c317a9c",
   "metadata": {},
   "source": [
    "# Simple Linear Iterative Clustering (SLIC) روش دسته بندی تکرار شونده خطی ساده\n",
    "\n",
    " قرار داردsegmentation وقسمت sikit-image این ابزار در کتابخانه "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5697706",
   "metadata": {},
   "source": [
    " وبر اساس شباهت رنگی،پیکسل های سازنده تصویر را به صورت سوپر پیکسل های مجزا تقسیم بندی میکندk-means این تابع به کمک الگوریتم خوشه بندی \n",
    "    \n",
    "    وبه هر سوپر پیکسل یک شماره میدهد \n",
    "    \n",
    "# labels = slic(image,n_segments,compactness,max_iter,sigma,enforce_connectivity,max_size_factor,slic_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5a175",
   "metadata": {},
   "source": [
    "image =  floatتصویراز نوع \n",
    "\n",
    "n_segments = پیشفرض100-تعداد سوپرپیکسل هایی که باید روی تصویر پیدا شوند\n",
    "\n",
    "compactness =پیشفرض 10-میزان تعادل بین رنگ های قسمت های مجاوربا یکدیگر\n",
    "\n",
    "max_iter = k-meansپیشفرض10-تعداد دفعات تکرار الگوریتم\n",
    "\n",
    "sigma = پیشفرض 0-اندازه ماتریس هسته برای فیلتر گاوسی\n",
    "\n",
    "enforce_connectivity = وبیان میکند قسمت های تقسیم شده در بیان به یکدیگر متصل خواهند شد-Trueپیشفرض\n",
    "\n",
    "max_size_factor = نسبت حداکثر اندازه قسمت های متصل شده با مقدار اولیه3 است\n",
    "\n",
    "slic_zero = است false در هنگام تقسیم بندی که پیشفرض zeroاجرا کردن پارامتر \n",
    "\n",
    "labels = ماتریسی شامل شماره برچسب های داده شده به پیکسل های تصویر ورودی"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6998af6",
   "metadata": {},
   "source": [
    " سوپر پیکسل مربوطه را از تصویرANDبرای دستیابی به سوپر پیکسل ها کافی است هر سوپر پیکسل بر حسب اندیسش روی یک ماسک هم اندازه تصویر ورودی رسم وبا عملگر\n",
    "    \n",
    "    استخراج کرد\n",
    "    \n",
    "# mark_boundaries(image,label_img,color,outline_color)\n",
    "\n",
    "image =تصویر اصلی\n",
    "\n",
    "label_img = slicخروجی\n",
    "\n",
    "color = که بصورت پیشفرض برابر(0و1و1)استRGBرنگ مرزهای سوپر پیکسل ها برحسب \n",
    "\n",
    "outline_color = رنگی که پیرامون هر سوپر پیکسل رسم میشود\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86d308",
   "metadata": {},
   "source": [
    "مثال:تقسیم بندی تصویر به صورت سوپر پیکسلی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"pelak1.png\")\n",
    "#print(cv2.mean(img))\n",
    "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img2 = img_as_float(img2) #floatتبدیل تصویر به تایپ\n",
    "\n",
    "segments = slic(img2,n_segments=2,sigma=5)\n",
    "#print(segments)#خروجی ماتریس برچسب گذاری شده است \n",
    "fig = plt.figure(\"SuperPixsels\")\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(mark_boundaries(img2,segments,(0,1,1),0))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "#print(np.unique(segments))\n",
    "for segval in (np.unique(segments)):\n",
    "    mask = np.zeros(img.shape[:2],dtype = 'uint8')\n",
    "    mask[segments==segval] = 255\n",
    "   # print(mask)\n",
    "    cv2.imshow(\"Mask\",mask)\n",
    "    cv2.imshow(\"Applied\",cv2.bitwise_and(img,img,mask=mask))\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7485d",
   "metadata": {},
   "source": [
    "مثال:تبدیل تصاویر معمولی به حالت هنری"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fbdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic#مرحله دوم\n",
    "from skimage.segmentation import mark_boundaries#مرحله سوم\n",
    "from skimage.util import img_as_float#مرحله اول\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def parisma(x):\n",
    "    global image,img_f,result\n",
    "    segments = slic(img_f,n_segments=n,compactness=c,max_num_iter=m,sigma=s,\n",
    "                    enforce_connectivity=enf,max_size_factor=maxs,slic_zero=sz)\n",
    "    result = np.zeros(image.shape,dtype=\"uint8\")\n",
    "    for segval in (np.unique(segments)):\n",
    "        mask = np.zeros(image.shape[:2],dtype=\"uint8\")\n",
    "        mask[segments==segval] = 255\n",
    "        suppix = cv2.bitwise_and(image,image,mask=mask)\n",
    "        (b,g,r) = cv2.mean(suppix,mask=mask)[:3]#میانگین پیکسل های تصویر جایی که ماسک حضور دارد\n",
    "        suppix[:] = (b,g,r)\n",
    "        suppix = cv2.bitwise_and(suppix,suppix,mask=mask)\n",
    "        result = cv2.add(result,suppix)\n",
    "    result = mark_boundaries(result,segments,1,1)\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"ART Image\")\n",
    "cv2.namedWindow(\"Settings\")\n",
    "cv2.createTrackbar(\"SuperPixels\",\"Settings\",100,1000,parisma)\n",
    "cv2.createTrackbar(\"compactness\",\"Settings\",10,100,parisma)\n",
    "cv2.createTrackbar(\"max_iter\",\"Settings\",10,20,parisma)\n",
    "cv2.createTrackbar(\"sigma\",\"Settings\",0,20,parisma)\n",
    "cv2.createTrackbar(\"enforce\",\"Settings\",1,1,parisma)\n",
    "cv2.createTrackbar(\"max_size_factor\",\"Settings\",3,20,parisma)\n",
    "cv2.createTrackbar(\"slic_zero\",\"Settings\",0,1,parisma)\n",
    "\n",
    "image = cv2.imread(\"sample.jpeg\")\n",
    "img_f = img_as_float(image)\n",
    "result = np.zeros(image.shape,dtype=\"uint8\")\n",
    "\n",
    "while (True):\n",
    "    cv2.imshow(\"ART Image\",result)\n",
    "    n = cv2.getTrackbarPos(\"SuperPixels\",\"Settings\")\n",
    "    c = cv2.getTrackbarPos(\"compactness\",\"Settings\")\n",
    "    m = cv2.getTrackbarPos(\"max_iter\",\"Settings\")\n",
    "    s = cv2.getTrackbarPos(\"sigma\",\"Settings\")\n",
    "    enf = cv2.getTrackbarPos(\"enforce\",\"Settings\")\n",
    "    maxs = cv2.getTrackbarPos(\"max_size_factor\",\"Settings\")\n",
    "    sz = cv2.getTrackbarPos(\"slic_zero\",\"Settings\")\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3704ea",
   "metadata": {},
   "source": [
    "# الگوریتم آبگیر"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82f07a",
   "metadata": {},
   "source": [
    " یک الگوریتم کلاسیک در زمینه تقسیم بندی تصویر است ونام خود را از روش زهکشی در زمین شناسی گرفته استWatershed آبگیریا \n",
    "    \n",
    "برخی مواقع در پردازش تصویر اجسام با یگدیگر همپوشانی دارنددر این شرایط تعداد کانتورها از تعداد کل اجسام کمتر بوده ونتیجه پردازش اشتباه خواهد بود\n",
    "\n",
    "در این زمان از الگوریتم آبگیر استفاده کنید\n",
    "\n",
    "این الگوریتم برای هر جسم یک محدوده مشخص میکند سپس بر پایه اطلاعاتی مانندمرکز،محیط یا مساحت حوضه ها،حوضه های اجسام دارای همپوشانی را از یکدیگر\n",
    "\n",
    "جدا کرده وبدین ترتیب اجسام دارای همپوشانی را ازیکدیگر جدا میکند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef35b94",
   "metadata": {},
   "source": [
    "# OpenCv مراحل الگوریتم آبگیر در "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2ad6f",
   "metadata": {},
   "source": [
    "# 1. پیداکردن فاصله هر پیکسل 1(سفیدرنگ)تا نزدیک ترین پیکسل صفر(سیاه رنگ)درون تصویر\n",
    "\n",
    "dst = cv2.distanceTransform(src,distanceType,maskSize)\n",
    "\n",
    "src = تصویر باینری که باید ازنوع 8 بیت باشدthreshold\n",
    "\n",
    "distanceType = روش محاسبه فاصله (DIST_L1,DIST_L2,DIST_C)\n",
    "\n",
    "maskSize = اندازه ابعاد ماسک که باید بصورت مربعی 3*3یا 5*5 یا... وارد کردن اندازه یکی از ابعاد کافی است\n",
    "\n",
    "dst = تصویر یک کاناله 32بیتی و هم اندازه تصویر ورودی\n",
    "\n",
    "scipy.ndimage.distance_transform_edt() تابع بالا معادل تابع روبرو است\n",
    "\n",
    "# 2.براساس فواصل مشخص شده باید قله های اجسام درون تصویر راپیداکنید\n",
    "\n",
    "برای اینکار میتوانید از تابع آستانه گیری برحسب بیشترین فاصله محاسبه شده استفاده کنید یا\n",
    "\n",
    "dst = skimage.feature.peak_local_max(image,min_distance,indices,labels)میتوان روش ساده تر روبرو را انتخاب کرد\n",
    "\n",
    "این تابع فاصله محاسبه شده در قسمت قبل وکمترین فاصله بین قله هارا بعنوان ورودی دریافت کرده وآرایه ای از مختصات قله ها یا تصویر باینری شامل قله ها را برمیگرداند\n",
    "\n",
    "image = تصویر ورودی\n",
    "\n",
    "min_distance = پیشفرض 1است،کمترین فاصله بین 2 قله که هرچه کمتر باشد تعداد قله ها بیشتر میشود\n",
    "\n",
    "indices = باشد تصویری برمیگرداند که قله ها رانمایش میدهدFalseباشد آرایه ای برمیگرداند که مختصات قله ها را نشان میدهداگرTrueاگر\n",
    "\n",
    "labels =باشدthresholdاین پارامتر مانند ماسک عمل میکند و میتواند خروجی توابعی مانند \n",
    "\n",
    "dst = خروجی مختصات قله ها یا تصویری که قله هارا نمایش میدهد\n",
    "\n",
    "# 3.در این مرحله روی تپه ها برچسب زده میشود\n",
    "\n",
    "markers = cv2.connectedComponents(dst,connectivity=8,ltype=cv2.CV_32S)[1]\n",
    "\n",
    "یا\n",
    "\n",
    "markers = scipy.ndimage.labels(dst,kernel)[0]\n",
    "\n",
    "# 4 .موجود است استفاده میشودOpenCvکه درWatershed درپایان ازتابع \n",
    "\n",
    "این تابع تصویر اولیه وآرایه شامل برچسب ها را میگیرد وبا اجرای پردازش ها و بروزرسانی مداوم نشانه گرها،اجسام داخل تصویر را شناسایی کرده وبه هر یک برچسبی را اختصاص میدهد\n",
    "\n",
    "خروجی نهایی آرایه ای حاوی این برچسب هاست\n",
    "\n",
    "labels = cv2.watershed(image,markers)\n",
    "\n",
    "image = تصویر8بیتی و3کاناله\n",
    "\n",
    "markers = آرایه شامل برچسب ها\n",
    "\n",
    "labels = برچسب هایی که توسط الگوریتم آبگیر به پیکسل های سازنده تصاویر نسبت داده میشوند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5633c57",
   "metadata": {},
   "source": [
    "# scikit-images مراحل الگوریتم آبگیر در\n",
    "\n",
    "در این تابع بخاطر استفاده از یادگیری ماشین دقت وسرعت عمل بیشتر استOpenCvبرخلاف\n",
    "\n",
    "مراحل 1 تا 3 مانند قبل انجام میشود و فقط مرحله 4 متفاوت است\n",
    "\n",
    "labels = skimage.segmentation.watershed(image,markers,mask)\n",
    "\n",
    "image = وارد شود-image تصویر8بیتی و3کاناله این تابع ابتدا قسمت های کم ارزش را ارزش گذاری میکند پس تصویر باید بصورت\n",
    "\n",
    "markers = آرایه شامل برچسب ها\n",
    "\n",
    "mask = پارامتر دلخواه که در افزایش کیفیت تصویر خروجی تاثیر دارد\n",
    "\n",
    "labels = برچسب هایی که توسط الگوریتم آبگیر به پیکسل های سازنده تصاویر نسبت داده میشوند\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e0676",
   "metadata": {},
   "source": [
    "مثال :شمارش تعداد سکه ها در تصویر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31537cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "################################################thresholding مرحله اول\n",
    "image = cv2.imread(\"p.png\")\n",
    "clone1 = image.copy()\n",
    "clone2 = image.copy()\n",
    "filtered = cv2.pyrMeanShiftFiltering(image, 21, 51)\n",
    "gray = cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "method1 = cv2.THRESH_BINARY_INV\n",
    "method2 = cv2.THRESH_OTSU\n",
    "thresh = cv2.threshold(gray, 0, 255, method1 | method2)[1]\n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "opening = cv2.erode(thresh, kernel, iterations = 2)\n",
    "cv2.imshow(\"threshold\", opening)\n",
    "\n",
    "#contours##############################################################################تقسیم برندی براساس کانتورها\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "method = cv2.RETR_EXTERNAL\n",
    "mode = cv2.CHAIN_APPROX_SIMPLE\n",
    "\n",
    "cnts = cv2.findContours(opening.copy(), method, mode)[0]\n",
    "print(len(cnts))\n",
    "for i, c in enumerate(cnts):\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "    cv2.circle(clone1, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "    cv2.putText(clone1, \"{}\".format(i), (int(x) - 10, int(y)), font, 0.6, (255, 255, 255), 2)\n",
    "cv2.imshow(\"Contours\", clone1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#opencv##############################################################################opencv تقسیم بندی با الگوریتم آبگیر\n",
    "\n",
    "D = cv2.distanceTransform(opening, cv2.DIST_L2, 5)#پیداکردن فاصله پیکسل های سفید تا نزدیکترین پیکسل مشکی\n",
    "#print(D)\n",
    "(_ , localMax) = cv2.threshold(D, 0.7 * D.max(), 255, 0)#رسم قله ها روی تصویر باینری بااستفاده از بیشترین فاصله و آستانه گیری\n",
    "(_ , markers) = cv2.connectedComponents(np.uint8(localMax))#برچسب گذاری اجسام\n",
    "labels = cv2.watershed(image, markers)\n",
    "print(\"unique segments: {} found\".format(len(np.unique(labels)) - 1))\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:\n",
    "        continue\n",
    "    mask = np.zeros(gray.shape, dtype = \"uint8\")\n",
    "    mask[labels == label] = 255\n",
    " \n",
    "    cnts = cv2.findContours(mask.copy(), method, mode)[-2]\n",
    "    c = max(cnts, key = cv2.contourArea)\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "    cv2.circle(clone2, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "    cv2.putText(clone2, \"{}\".format(label), (int(x) - 10, int(y)), font, 0.6, (255, 255, 255), 2)\n",
    "cv2.imshow(\"watershed in OpenCV\", clone2)\n",
    "cv2.waitKey(0)\n",
    "###############################################################################\n",
    "\n",
    "#D = ndimage.distance_transform_edt(opening)#پیداکردن فاصله پیکسل های سفید تا نزدیکترین پیکسل مشکی\n",
    "#localMax = peak_local_max(D, min_distance = 20,)# skimage  رسم قله ها روی تصویر باینری بااستفاده از بیشترین فاصله و\n",
    "\n",
    "markers = ndimage.label(localMax, structure = np.ones((3, 3)))[0]\n",
    "#print(markers)\n",
    "labels = watershed(-D, markers, mask = thresh)\n",
    "print(\"unique segments: {} found\".format(len(np.unique(labels)) - 1))\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:\n",
    "        continue\n",
    "    mask = np.zeros(gray.shape, dtype = \"uint8\")\n",
    "    mask[labels == label] = 255\n",
    " \n",
    "    cnts = cv2.findContours(mask.copy(), method, mode)[-2]\n",
    "    c = max(cnts, key = cv2.contourArea)\n",
    "    ((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "    cv2.circle(image, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "    cv2.putText(image, \"{}\".format(label), (int(x) - 10, int(y)), font, 0.6, (255, 255, 255), 2)\n",
    "cv2.imshow(\"watershed scikit-image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage\n",
    "help( ndimage.label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b7a19e",
   "metadata": {},
   "source": [
    "# جداکردن پیش زمینه از تصویر"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8573e37",
   "metadata": {},
   "source": [
    "پیش زمینه به جسم یا اجسامی در تصویر گفته میشود که بطور معمول جزیی از زمینه یا کلیت تصویر نیستند\n",
    "\n",
    "مثلا در یک خیابان ماشین و انسان هردو پیش زمینه هستند و خیابان ها ومغازه ها و پیاده رو ها زمینه محسوب میشوند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92efcba4",
   "metadata": {},
   "source": [
    "# grabCut الگوریتم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c51bca",
   "metadata": {},
   "source": [
    "# مراحل الگوریتم\n",
    "\n",
    "# 1. \n",
    "\n",
    "ابتدا تمام پیکسل های تصویر وارد الگوریتم شده،در این مرحله لازم است کاربر چند پیکسل از زمینه را با رنگ سیاه و برچسب 0وتعدادی از پیکسل های پیش زمینه رابا رنگ سفید  \n",
    "\n",
    "وبرچسب 1 نشانه گذاری کند(این نوع برچسب زنی که تا انتها برچسب ها تغییر نمیکندرا برچسب زنی سخت گویند)\n",
    "\n",
    "# 2.\n",
    "\n",
    "تعریف میکندکه در ابتدا تمام گره ها درگراف به S وپیش زمینهT گرافی طراحی میکند که درآن گره ها همان پیکسل های تصویر هستند،2گره مرجع بعنوان زمینهgrabCut الگوریتم\n",
    "\n",
    "این دو گره متصل هستندوهدف الگوریتم جدا کردن گره های متصل به این 2 گره مرجع است\n",
    "\n",
    "# 3.\n",
    "\n",
    "تابع انرژی،وزن بین گره ها ودو گره مرجع را تعیین میکندوزن میان پیکسل ها به کمک اطلاعات مربوط به لبه ها محاسبه میشود\n",
    "\n",
    "# 4.\n",
    "\n",
    "استفاده میشود این الگوریتم خط برش را بر اساس کمترین هزینه برشی پیدا میکندMin-Cut/Max-Flowدرپایان برای جدا سازی گره های زمینه و پیش زمینه از الگوریتم \n",
    "\n",
    "هزینه برش از جمع تمام وزن هایی که به خط برش متصل هستند محاسبه میشود\n",
    "\n",
    "# جداسازی را به2 روش انجام میدهدgrabCut الگوریتم \n",
    "\n",
    "1.روش مستطیلی با در اختیار داشتن مستطیلی که پیش زمینه بطور کامل در آن قرار گرفته است\n",
    "\n",
    "2. روش ماسک با در اختیار داشتن ماسکی که برخی پیکسل های آن دارای برچسب سخت هستند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceca04b",
   "metadata": {},
   "source": [
    "mask = cv2.grabCut(image,mask,rect,bgdModel,fdgModel,iterCount,mode)\n",
    "\n",
    "image = تصویر ورودی که باید از نو 8 بیتی و 3 کاناله باشد\n",
    "\n",
    "mask =  باشدGC_INIT_WITH_MASKباشد ماسک بعنوان خروجی ودر صورتی که برابرGC_INIT_WITH_RECTبرابر modeماسک یک کاناله و8 بیتی اگر پارامتر \n",
    "\n",
    "بعنوان ماسک ورودی در نظر گرفته شده و باید برخی ازپیکسل های پیش زمینه و زمینه آن به ترتیب بارنگ های سفید و سیاه مشخص شده باشند\n",
    "\n",
    "rect = این ورودی شامل مستطیلی است که پیش زمینه به طور کامل در آن قرار گرفته است\n",
    "\n",
    "bgdModel = np.zeros((1, 65), np.float64)آرایه ای که الگوریتم از آن بمنظور دخیره سازی اطلاعات مربوط به زمینه و پیش زمینه استفاده میکند\n",
    "\n",
    "fdgModel = np.zeros((1, 65), np.float64)آرایه ای که الگوریتم از آن بمنظور دخیره سازی اطلاعات مربوط به زمینه و پیش زمینه استفاده میکند\n",
    "\n",
    "iterCount = تعداد دفعاتی که الگوریتم اجرا میشود\n",
    "\n",
    "mode =روش جداسازی زمینه از پیش زمینه\n",
    "      \n",
    "   GC_INIT_WITH_RECT استفاده از مستطیلی که پیش زمینه کامل در آن باشد\n",
    "\n",
    "   GC_INIT_WITH_MASK استفاده از ماسکی که بعضی از پیکسل های زمینه و پیش زمینه در آن علامت گذاری شده باشند"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134ed1f",
   "metadata": {},
   "source": [
    "خروجیmask = ماسک باینری که هر پیکسل آن یکی از حالات زیر را دارد\n",
    "\n",
    "GC_BGD=آن پیکسل باید عضوی از زمینه بوده و برچسب 0 داشته باشد\n",
    "\n",
    "GC_FGD= آن پیکسل باید عضوی از پیش زمینه بوده و دارای برچسب 1 باشد\n",
    "\n",
    "GC_PR_BGD=آن پیکسل احتمال دارد عضوی از زمینه باشد در این صورت با برچسب 2 نمایش داده میشود\n",
    "\n",
    "GC_PR_FGD= آن پیکسل احتمال دارد عضوی از پیش زمینه باشد در این صورت با برچسب 3 نمایش داده میشود\n",
    "\n",
    "در پایان کافی است درون ماسک پیکسل های مربوط به پیش زمینه راانتخاب کرده وباقی پیکسل هارا حذف کنید"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa08b0",
   "metadata": {},
   "source": [
    "مثال :جداکردن پیش زمینه از تصویر به روش مستطیل"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bfcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "rect = []\n",
    "selected = \"Not Set\"\n",
    "def select(event, x, y, flags, param):\n",
    "    global rect, selected\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        rect.extend([x, y])  \n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        rect.extend([x, y])\n",
    "        selected = \"Set\"\n",
    "        print(rect)\n",
    "image = cv2.imread('p.png')     \n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", select)\n",
    "cv2.imshow(\"Image\", image)\n",
    "\n",
    "while(True):\n",
    "    if selected == \"Set\":\n",
    "        mask = np.zeros(image.shape[ : 2], np.uint8)\n",
    "        bgdModel = np.zeros((1, 65), np.float64)#برای ذخیره سازی اطلاعات زمینه یا پیش زمینه\n",
    "        fgdModel = np.zeros((1, 65), np.float64)#برای دخیره سازی اطلاعات زمینه یا پیش زمینه\n",
    "        cv2.grabCut(image, mask, tuple(rect), bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT)\n",
    "#مقادیر ماسک جاییکه 0یا2 باشد زمینه محسوب میشود و جاییکه 1یا3 باشد پیش زمینه         \n",
    "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')#تبدیل به فرمت تصویر اصلی\n",
    "       # print(image.shape)\n",
    "       # print(mask2.shape)\n",
    "        img = image * mask2[: , : , np.newaxis]#یک بعد به ماسک اضافه میکنیم برای برابری با ابعاد تصویر اصلی\n",
    "        cv2.imshow(\"Foreground Extraction\", img)\n",
    "        selected = \"Not Set\"\n",
    "        rect = []\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a81e80",
   "metadata": {},
   "source": [
    "# آرایه مربوط را یک بعد افزایش میدهدnumpy از کتابخانه newaxis تابع "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ff2b4",
   "metadata": {},
   "source": [
    "مثال :جداکردن پیش زمینه از تصویر به روش ماسک"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "black = [0, 0, 0]\n",
    "white = [255, 255, 255]\n",
    "draw_bg = {'color' : black, 'val' : 0}\n",
    "draw_fg = {'color' : white, 'val' : 1}\n",
    "rectangle = False\n",
    "rect_over = False\n",
    "drawing  =False\n",
    "value = draw_bg\n",
    "rect = (0, 0, 1, 1)\n",
    "rect_or_mask = 100\n",
    "\n",
    "def mouse(event, x, y, flags, param):\n",
    "    global img, img1, mask, rect, rectangle, rect_over\n",
    "    global ix, iy ,drawing, value, rect_or_mask\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        rectangle = True\n",
    "        ix, iy = x, y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if rectangle == True:\n",
    "            img = img1.copy()\n",
    "            cv2.rectangle(img, (ix, iy), (x, y), (255, 0, 0), 2)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        rectangle = False\n",
    "        rect_over = True\n",
    "        cv2.rectangle(img, (ix, iy), (x, y), (255, 0, 0), 2)\n",
    "        rect = (min(ix, x), min(iy, y), abs(ix - x), abs(iy - y))\n",
    "        rect_or_mask = 0\n",
    "     \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        if rect_over == False:\n",
    "            print(\"first draw rectangle \\n\")\n",
    "        else:\n",
    "            drawing = True\n",
    "            cv2.circle(img, (x, y), 2, value['color'], -1)\n",
    "            cv2.circle(mask, (x,y), 2, value['val'], -1)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            cv2.circle(img, (x, y), 2, value['color'], -1)\n",
    "            cv2.circle(mask, (x, y), 2, value['val'], -1)\n",
    "    elif event == cv2.EVENT_RBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.circle(img, (x, y), 2, value['color'], -1)\n",
    "        cv2.circle(mask, (x, y), 2, value['val'] , -1)\n",
    "\n",
    "img = cv2.imread('camel.jpg')\n",
    "img1 = img.copy()\n",
    "mask = np.zeros(img.shape[ : 2], dtype = np.uint8)\n",
    "output = np.zeros(img.shape, np.uint8)\n",
    "\n",
    "cv2.namedWindow(\"Input\")\n",
    "cv2.namedWindow(\"Output\")\n",
    "cv2.setMouseCallback(\"Input\", mouse)\n",
    "print(\" Draw a rectangle around the object using left mouse button \\n\")\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow(\"Input\", img)\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if (k == 27):\n",
    "        break\n",
    "    \n",
    "    elif k == ord('g'):\n",
    "        print(\"GrabCut algorithm is running. Please wait \\n\")\n",
    "        if (rect_or_mask == 0):\n",
    "            bgdmodel = np.zeros((1, 65), np.float64)\n",
    "            fgdmodel = np.zeros((1, 65), np.float64)\n",
    "            cv2.grabCut(img1, mask, rect, bgdmodel, fgdmodel, 10, cv2.GC_INIT_WITH_RECT)\n",
    "            rect_or_mask = 1\n",
    "            \n",
    "        elif (rect_or_mask == 1):\n",
    "            bgdmodel = np.zeros((1, 65), np.float64)\n",
    "            fgdmodel = np.zeros((1, 65), np.float64)\n",
    "            cv2.grabCut(img1, mask, None, bgdmodel, fgdmodel, 10, cv2.GC_INIT_WITH_MASK)\n",
    "        print(\"GrabCut algorithm is over \\n\")\n",
    "        \n",
    "    elif k == ord(\"0\"):\n",
    "        print(\" mark background regions with right mouse button \\n\")\n",
    "        value = draw_bg\n",
    "        \n",
    "    elif k == ord('1'):\n",
    "        print(\" mark foreground regions with right mouse button \\n\")\n",
    "        value = draw_fg\n",
    "    \n",
    "    mask2 = np.where((mask == 0) | (mask == 2), 0, 1).astype('uint8')\n",
    "    output = img1 * mask2[: , : , np.newaxis]\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46473b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
